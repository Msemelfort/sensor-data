{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a3d5a91",
   "metadata": {},
   "source": [
    "<h1 style = 'color:blue;text-align:center';> ISAT 341: Machine Learning and Data Science </h1>\n",
    "<h2 style = 'color:purple;text-align:center';> Project: Machine Learning Confidential Sensor Data</h2>\n",
    "<img src='images/machine_learning.jpg' width=200; height=200>\n",
    "<h3 style = 'color:teal;text-align:center';> Working with real-world datasets<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2eae7",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "#### To demonstrate the ability to complete an end-to-end data science / machine learning project using real-world data by following and implementing the main machine learning checklist steps that lead to a solution, namely:\n",
    "- Frame the problem and look at the big picture.\n",
    "- Get the data.\n",
    "- Explore the data to gain insights.\n",
    "- Prepare the data to expose the underlying data patterns to Machine Learning algorithms.\n",
    "- Explore many different models and short-list the best ones.\n",
    "- Fine-tune your models and combine them into a great solution.\n",
    "- Present your solution.\n",
    "- Launch, monitor, and maintain your system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265b37f",
   "metadata": {},
   "source": [
    "### Frame the problem\n",
    "\n",
    "<img src='images/sensor_array.jpg' width=200; height=200>\n",
    "\n",
    "### Sensor Data\n",
    "The data source as well as the exact nature of the data is confidential. Each data instance contains 12 real-valued input attributes. Each input\n",
    "attribute represents a sensor designed to detect the presence of one of two groups of substances. As an alternative, the sensor readings may\n",
    "represent a 'false alarm'.\n",
    "- Substance 1 is represented by the value 'one' in the class attribute column.\n",
    "- Substance 2 is represented by the value 'two' in the class attribute column.\n",
    "- A false alarm is represented by the value 'three' in the class attribute column.\n",
    "The problem is framed as a supervised learning problem: Predict the class of a substance from sensor data using the given measurements in\n",
    "the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2461d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e9445",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "### 1) TO DO: Use Pandas to load your data into a dataframe\n",
    "\n",
    "Display the first ten rows after you load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd37f09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.406</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>5.691</td>\n",
       "      <td>5.906</td>\n",
       "      <td>1.763</td>\n",
       "      <td>2.726</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>1.859</td>\n",
       "      <td>5.083</td>\n",
       "      <td>5.503</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.680</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>5.461</td>\n",
       "      <td>5.923</td>\n",
       "      <td>1.589</td>\n",
       "      <td>2.799</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.821</td>\n",
       "      <td>5.099</td>\n",
       "      <td>5.601</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.738</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>5.680</td>\n",
       "      <td>5.916</td>\n",
       "      <td>1.844</td>\n",
       "      <td>2.798</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>1.759</td>\n",
       "      <td>5.127</td>\n",
       "      <td>5.535</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.503</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>5.703</td>\n",
       "      <td>-9999.000</td>\n",
       "      <td>1.711</td>\n",
       "      <td>2.856</td>\n",
       "      <td>1.1500</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>1.736</td>\n",
       "      <td>5.094</td>\n",
       "      <td>5.452</td>\n",
       "      <td>0.7690</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.744</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>5.532</td>\n",
       "      <td>5.911</td>\n",
       "      <td>1.792</td>\n",
       "      <td>2.886</td>\n",
       "      <td>1.0310</td>\n",
       "      <td>0.5627</td>\n",
       "      <td>1.868</td>\n",
       "      <td>4.989</td>\n",
       "      <td>5.382</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.524</td>\n",
       "      <td>0.6311</td>\n",
       "      <td>5.773</td>\n",
       "      <td>5.822</td>\n",
       "      <td>1.803</td>\n",
       "      <td>2.800</td>\n",
       "      <td>1.0490</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>1.885</td>\n",
       "      <td>5.100</td>\n",
       "      <td>5.479</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.570</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.887</td>\n",
       "      <td>1.708</td>\n",
       "      <td>2.894</td>\n",
       "      <td>1.0830</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>1.807</td>\n",
       "      <td>5.062</td>\n",
       "      <td>5.336</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.489</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>5.790</td>\n",
       "      <td>5.900</td>\n",
       "      <td>1.849</td>\n",
       "      <td>2.919</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>1.809</td>\n",
       "      <td>5.216</td>\n",
       "      <td>5.555</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.503</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.686</td>\n",
       "      <td>5.892</td>\n",
       "      <td>1.714</td>\n",
       "      <td>2.822</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>1.840</td>\n",
       "      <td>5.001</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.425</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.732</td>\n",
       "      <td>5.912</td>\n",
       "      <td>1.793</td>\n",
       "      <td>2.726</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.6104</td>\n",
       "      <td>1.749</td>\n",
       "      <td>5.020</td>\n",
       "      <td>5.514</td>\n",
       "      <td>0.8081</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input 1  Input 2  Input 3   Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0    4.406   0.6116    5.691     5.906    1.763    2.726   0.9607   0.6055   \n",
       "1    4.680   0.5322    5.461     5.923    1.589    2.799   0.9937   0.6250   \n",
       "2    4.738   0.5298    5.680     5.916    1.844    2.798   1.0280   0.6238   \n",
       "3    4.503   0.5273    5.703 -9999.000    1.711    2.856   1.1500   0.6201   \n",
       "4    4.744   0.5884    5.532     5.911    1.792    2.886   1.0310   0.5627   \n",
       "5    4.524   0.6311    5.773     5.822    1.803    2.800   1.0490   0.6836   \n",
       "6    4.570   0.4834    5.804     5.887    1.708    2.894   1.0830   0.4919   \n",
       "7    4.489   0.5054    5.790     5.900    1.849    2.919   0.9082   0.6055   \n",
       "8    4.503   0.6091    5.686     5.892    1.714    2.822   1.0300   0.6079   \n",
       "9    4.425   0.6091    5.732     5.912    1.793    2.726   1.0950   0.6104   \n",
       "\n",
       "   Input 9  Input 10  Input 11  Input 12 class  \n",
       "0    1.859     5.083     5.503    0.7544   one  \n",
       "1    1.821     5.099     5.601    0.9546   one  \n",
       "2    1.759     5.127     5.535    0.7275   one  \n",
       "3    1.736     5.094     5.452    0.7690   one  \n",
       "4    1.868     4.989     5.382    0.6665   one  \n",
       "5    1.885     5.100     5.479    0.6958   one  \n",
       "6    1.807     5.062     5.336    0.8447   one  \n",
       "7    1.809     5.216     5.555    0.6897   one  \n",
       "8    1.840     5.001     5.360    0.9521   one  \n",
       "9    1.749     5.020     5.514    0.8081   one  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Sensor_Data_Confidential_341Project_DataSet6 (1).csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b8a32",
   "metadata": {},
   "source": [
    "### 2) TO DO: Use the dataframe describe method dataframe.describe() to display some summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3363d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-118.477820</td>\n",
       "      <td>-115.190205</td>\n",
       "      <td>-101.885998</td>\n",
       "      <td>-81.856424</td>\n",
       "      <td>-116.071233</td>\n",
       "      <td>-115.554978</td>\n",
       "      <td>-85.817986</td>\n",
       "      <td>-131.942065</td>\n",
       "      <td>-100.919491</td>\n",
       "      <td>-73.600490</td>\n",
       "      <td>-89.802421</td>\n",
       "      <td>-72.618565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1098.964058</td>\n",
       "      <td>1075.906369</td>\n",
       "      <td>1028.917998</td>\n",
       "      <td>926.674967</td>\n",
       "      <td>1075.810024</td>\n",
       "      <td>1075.866400</td>\n",
       "      <td>926.304277</td>\n",
       "      <td>1142.867792</td>\n",
       "      <td>1003.960864</td>\n",
       "      <td>870.738138</td>\n",
       "      <td>953.021476</td>\n",
       "      <td>870.830680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.052000</td>\n",
       "      <td>0.800800</td>\n",
       "      <td>4.852000</td>\n",
       "      <td>3.937000</td>\n",
       "      <td>0.461400</td>\n",
       "      <td>0.648200</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>1.427000</td>\n",
       "      <td>1.107000</td>\n",
       "      <td>0.787400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.075000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.326000</td>\n",
       "      <td>5.013000</td>\n",
       "      <td>0.784900</td>\n",
       "      <td>1.572000</td>\n",
       "      <td>0.538300</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.679900</td>\n",
       "      <td>1.965000</td>\n",
       "      <td>1.273000</td>\n",
       "      <td>4.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.906000</td>\n",
       "      <td>5.583000</td>\n",
       "      <td>5.555000</td>\n",
       "      <td>1.238000</td>\n",
       "      <td>2.136000</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>1.124000</td>\n",
       "      <td>4.915000</td>\n",
       "      <td>1.807000</td>\n",
       "      <td>5.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.105000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>5.944000</td>\n",
       "      <td>6.011000</td>\n",
       "      <td>2.571000</td>\n",
       "      <td>3.638000</td>\n",
       "      <td>2.446000</td>\n",
       "      <td>1.199000</td>\n",
       "      <td>2.278000</td>\n",
       "      <td>5.312000</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Input 1      Input 2      Input 3      Input 4      Input 5  \\\n",
       "count  1965.000000  1965.000000  1965.000000  1965.000000  1965.000000   \n",
       "mean   -118.477820  -115.190205  -101.885998   -81.856424  -116.071233   \n",
       "std    1098.964058  1075.906369  1028.917998   926.674967  1075.810024   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       3.052000     0.800800     4.852000     3.937000     0.461400   \n",
       "50%       4.075000     1.488000     5.326000     5.013000     0.784900   \n",
       "75%       4.496000     2.906000     5.583000     5.555000     1.238000   \n",
       "max       5.105000     4.675000     5.944000     6.011000     2.571000   \n",
       "\n",
       "           Input 6      Input 7      Input 8      Input 9     Input 10  \\\n",
       "count  1965.000000  1965.000000  1965.000000  1965.000000  1965.000000   \n",
       "mean   -115.554978   -85.817986  -131.942065  -100.919491   -73.600490   \n",
       "std    1075.866400   926.304277  1142.867792  1003.960864   870.738138   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       0.648200     0.307600     0.185500     0.423600     1.427000   \n",
       "50%       1.572000     0.538300     0.290500     0.679900     1.965000   \n",
       "75%       2.136000     0.913100     0.454100     1.124000     4.915000   \n",
       "max       3.638000     2.446000     1.199000     2.278000     5.312000   \n",
       "\n",
       "          Input 11     Input 12  \n",
       "count  1965.000000  1965.000000  \n",
       "mean    -89.802421   -72.618565  \n",
       "std     953.021476   870.830680  \n",
       "min   -9999.000000 -9999.000000  \n",
       "25%       1.107000     0.787400  \n",
       "50%       1.273000     4.867000  \n",
       "75%       1.807000     5.399000  \n",
       "max       5.640000    20.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0909c1",
   "metadata": {},
   "source": [
    "### Comments on above summary of data\n",
    "Examine the data and note that when a sensor temporarily goes offline, it records a BAD data value of -9999. This can be seen in the minimum\n",
    "recorded values for each sensor. Before we continue our preliminary data analysis, this bad data must be removed.\n",
    "You should also take note of the count, mean, standard deviation and the maximum data values for each sensor. The bad data value\n",
    "recordings when the senors go offline have a large impact on these simple descriptive statistical summaries. Also, the wide range of the data\n",
    "values will require some sort of scaling of the data before training a machine learing model.\n",
    "Finally, the class labels are not numeric but are strings ('one', 'two' and 'three') that we call categorical class labels. We will need to convert\n",
    "them to integers before we feed them to a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e7fe9",
   "metadata": {},
   "source": [
    "## Data Cleansing\n",
    "### 3) TO DO: Display the shape of your dataframe data in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5d8d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1965, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248c0d6",
   "metadata": {},
   "source": [
    "### 4) TO DO: Use Pandas dataframe to find bad or missing data.\n",
    "The bad data can be located and replaced using pandas and numpy. In the cell below, use code to find and replace the bad data (-9999\n",
    "values) with numpy nan values (nan means not a number). Then use the dataframe to drop the rows with the nan signatures. This may\n",
    "significantly reduce your dataset size so you should display the shape of the data to see its new size. Also, again, display the first ten rows of\n",
    "the data with the dataframe.\n",
    "- Enter your code in the cell below to implement the drop, replace and display.\n",
    "- Enter your code in the cell immediately following the output of the dataframe display to show the new shape of data in the\n",
    "dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f6588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.406</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>5.691</td>\n",
       "      <td>5.906</td>\n",
       "      <td>1.763</td>\n",
       "      <td>2.726</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>1.859</td>\n",
       "      <td>5.083</td>\n",
       "      <td>5.503</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.680</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>5.461</td>\n",
       "      <td>5.923</td>\n",
       "      <td>1.589</td>\n",
       "      <td>2.799</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.821</td>\n",
       "      <td>5.099</td>\n",
       "      <td>5.601</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.738</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>5.680</td>\n",
       "      <td>5.916</td>\n",
       "      <td>1.844</td>\n",
       "      <td>2.798</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>1.759</td>\n",
       "      <td>5.127</td>\n",
       "      <td>5.535</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.744</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>5.532</td>\n",
       "      <td>5.911</td>\n",
       "      <td>1.792</td>\n",
       "      <td>2.886</td>\n",
       "      <td>1.0310</td>\n",
       "      <td>0.5627</td>\n",
       "      <td>1.868</td>\n",
       "      <td>4.989</td>\n",
       "      <td>5.382</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.524</td>\n",
       "      <td>0.6311</td>\n",
       "      <td>5.773</td>\n",
       "      <td>5.822</td>\n",
       "      <td>1.803</td>\n",
       "      <td>2.800</td>\n",
       "      <td>1.0490</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>1.885</td>\n",
       "      <td>5.100</td>\n",
       "      <td>5.479</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.570</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.887</td>\n",
       "      <td>1.708</td>\n",
       "      <td>2.894</td>\n",
       "      <td>1.0830</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>1.807</td>\n",
       "      <td>5.062</td>\n",
       "      <td>5.336</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.489</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>5.790</td>\n",
       "      <td>5.900</td>\n",
       "      <td>1.849</td>\n",
       "      <td>2.919</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>1.809</td>\n",
       "      <td>5.216</td>\n",
       "      <td>5.555</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.503</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.686</td>\n",
       "      <td>5.892</td>\n",
       "      <td>1.714</td>\n",
       "      <td>2.822</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>1.840</td>\n",
       "      <td>5.001</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.425</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.732</td>\n",
       "      <td>5.912</td>\n",
       "      <td>1.793</td>\n",
       "      <td>2.726</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.6104</td>\n",
       "      <td>1.749</td>\n",
       "      <td>5.020</td>\n",
       "      <td>5.514</td>\n",
       "      <td>0.8081</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.534</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>5.411</td>\n",
       "      <td>5.896</td>\n",
       "      <td>1.760</td>\n",
       "      <td>3.008</td>\n",
       "      <td>1.1160</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>1.854</td>\n",
       "      <td>4.971</td>\n",
       "      <td>5.503</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0     4.406   0.6116    5.691    5.906    1.763    2.726   0.9607   0.6055   \n",
       "1     4.680   0.5322    5.461    5.923    1.589    2.799   0.9937   0.6250   \n",
       "2     4.738   0.5298    5.680    5.916    1.844    2.798   1.0280   0.6238   \n",
       "4     4.744   0.5884    5.532    5.911    1.792    2.886   1.0310   0.5627   \n",
       "5     4.524   0.6311    5.773    5.822    1.803    2.800   1.0490   0.6836   \n",
       "6     4.570   0.4834    5.804    5.887    1.708    2.894   1.0830   0.4919   \n",
       "7     4.489   0.5054    5.790    5.900    1.849    2.919   0.9082   0.6055   \n",
       "8     4.503   0.6091    5.686    5.892    1.714    2.822   1.0300   0.6079   \n",
       "9     4.425   0.6091    5.732    5.912    1.793    2.726   1.0950   0.6104   \n",
       "10    4.534   0.6287    5.411    5.896    1.760    3.008   1.1160   0.6116   \n",
       "\n",
       "    Input 9  Input 10  Input 11  Input 12 class  \n",
       "0     1.859     5.083     5.503    0.7544   one  \n",
       "1     1.821     5.099     5.601    0.9546   one  \n",
       "2     1.759     5.127     5.535    0.7275   one  \n",
       "4     1.868     4.989     5.382    0.6665   one  \n",
       "5     1.885     5.100     5.479    0.6958   one  \n",
       "6     1.807     5.062     5.336    0.8447   one  \n",
       "7     1.809     5.216     5.555    0.6897   one  \n",
       "8     1.840     5.001     5.360    0.9521   one  \n",
       "9     1.749     5.020     5.514    0.8081   one  \n",
       "10    1.854     4.971     5.503    0.7507   one  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(-9999, np.nan)\n",
    "df = df.dropna()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b108ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1732, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of data after cleansing\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1cf3f7",
   "metadata": {},
   "source": [
    "### 5) TO DO: Use pandas correlation method to find the two features (inputs) with the highest correlation\n",
    "#### Enter your answers in the cell immediately following the output correlation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "388affaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Input 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.594607</td>\n",
       "      <td>0.925093</td>\n",
       "      <td>0.938600</td>\n",
       "      <td>0.752668</td>\n",
       "      <td>0.892669</td>\n",
       "      <td>0.691514</td>\n",
       "      <td>0.665115</td>\n",
       "      <td>0.738312</td>\n",
       "      <td>0.686954</td>\n",
       "      <td>0.454579</td>\n",
       "      <td>-0.155881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 2</th>\n",
       "      <td>-0.594607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.539680</td>\n",
       "      <td>-0.545516</td>\n",
       "      <td>-0.447404</td>\n",
       "      <td>-0.662066</td>\n",
       "      <td>-0.455466</td>\n",
       "      <td>-0.458217</td>\n",
       "      <td>-0.459051</td>\n",
       "      <td>-0.417590</td>\n",
       "      <td>-0.325162</td>\n",
       "      <td>-0.044529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 3</th>\n",
       "      <td>0.925093</td>\n",
       "      <td>-0.539680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879927</td>\n",
       "      <td>0.638938</td>\n",
       "      <td>0.797819</td>\n",
       "      <td>0.582291</td>\n",
       "      <td>0.558866</td>\n",
       "      <td>0.635272</td>\n",
       "      <td>0.583224</td>\n",
       "      <td>0.383981</td>\n",
       "      <td>-0.156283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 4</th>\n",
       "      <td>0.938600</td>\n",
       "      <td>-0.545516</td>\n",
       "      <td>0.879927</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803925</td>\n",
       "      <td>0.860074</td>\n",
       "      <td>0.723526</td>\n",
       "      <td>0.711352</td>\n",
       "      <td>0.802887</td>\n",
       "      <td>0.751508</td>\n",
       "      <td>0.511918</td>\n",
       "      <td>-0.165669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 5</th>\n",
       "      <td>0.752668</td>\n",
       "      <td>-0.447404</td>\n",
       "      <td>0.638938</td>\n",
       "      <td>0.803925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852378</td>\n",
       "      <td>0.924553</td>\n",
       "      <td>0.913517</td>\n",
       "      <td>0.971557</td>\n",
       "      <td>0.881586</td>\n",
       "      <td>0.697366</td>\n",
       "      <td>-0.219152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 6</th>\n",
       "      <td>0.892669</td>\n",
       "      <td>-0.662066</td>\n",
       "      <td>0.797819</td>\n",
       "      <td>0.860074</td>\n",
       "      <td>0.852378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773119</td>\n",
       "      <td>0.761403</td>\n",
       "      <td>0.853061</td>\n",
       "      <td>0.801882</td>\n",
       "      <td>0.664157</td>\n",
       "      <td>-0.190464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 7</th>\n",
       "      <td>0.691514</td>\n",
       "      <td>-0.455466</td>\n",
       "      <td>0.582291</td>\n",
       "      <td>0.723526</td>\n",
       "      <td>0.924553</td>\n",
       "      <td>0.773119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946761</td>\n",
       "      <td>0.874562</td>\n",
       "      <td>0.807780</td>\n",
       "      <td>0.526361</td>\n",
       "      <td>-0.234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 8</th>\n",
       "      <td>0.665115</td>\n",
       "      <td>-0.458217</td>\n",
       "      <td>0.558866</td>\n",
       "      <td>0.711352</td>\n",
       "      <td>0.913517</td>\n",
       "      <td>0.761403</td>\n",
       "      <td>0.946761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878703</td>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.548836</td>\n",
       "      <td>-0.250512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 9</th>\n",
       "      <td>0.738312</td>\n",
       "      <td>-0.459051</td>\n",
       "      <td>0.635272</td>\n",
       "      <td>0.802887</td>\n",
       "      <td>0.971557</td>\n",
       "      <td>0.853061</td>\n",
       "      <td>0.874562</td>\n",
       "      <td>0.878703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882846</td>\n",
       "      <td>0.762006</td>\n",
       "      <td>-0.239315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 10</th>\n",
       "      <td>0.686954</td>\n",
       "      <td>-0.417590</td>\n",
       "      <td>0.583224</td>\n",
       "      <td>0.751508</td>\n",
       "      <td>0.881586</td>\n",
       "      <td>0.801882</td>\n",
       "      <td>0.807780</td>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.882846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703079</td>\n",
       "      <td>-0.183873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 11</th>\n",
       "      <td>0.454579</td>\n",
       "      <td>-0.325162</td>\n",
       "      <td>0.383981</td>\n",
       "      <td>0.511918</td>\n",
       "      <td>0.697366</td>\n",
       "      <td>0.664157</td>\n",
       "      <td>0.526361</td>\n",
       "      <td>0.548836</td>\n",
       "      <td>0.762006</td>\n",
       "      <td>0.703079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input 12</th>\n",
       "      <td>-0.155881</td>\n",
       "      <td>-0.044529</td>\n",
       "      <td>-0.156283</td>\n",
       "      <td>-0.165669</td>\n",
       "      <td>-0.219152</td>\n",
       "      <td>-0.190464</td>\n",
       "      <td>-0.234400</td>\n",
       "      <td>-0.250512</td>\n",
       "      <td>-0.239315</td>\n",
       "      <td>-0.183873</td>\n",
       "      <td>-0.085909</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Input 1   Input 2   Input 3   Input 4   Input 5   Input 6  \\\n",
       "Input 1   1.000000 -0.594607  0.925093  0.938600  0.752668  0.892669   \n",
       "Input 2  -0.594607  1.000000 -0.539680 -0.545516 -0.447404 -0.662066   \n",
       "Input 3   0.925093 -0.539680  1.000000  0.879927  0.638938  0.797819   \n",
       "Input 4   0.938600 -0.545516  0.879927  1.000000  0.803925  0.860074   \n",
       "Input 5   0.752668 -0.447404  0.638938  0.803925  1.000000  0.852378   \n",
       "Input 6   0.892669 -0.662066  0.797819  0.860074  0.852378  1.000000   \n",
       "Input 7   0.691514 -0.455466  0.582291  0.723526  0.924553  0.773119   \n",
       "Input 8   0.665115 -0.458217  0.558866  0.711352  0.913517  0.761403   \n",
       "Input 9   0.738312 -0.459051  0.635272  0.802887  0.971557  0.853061   \n",
       "Input 10  0.686954 -0.417590  0.583224  0.751508  0.881586  0.801882   \n",
       "Input 11  0.454579 -0.325162  0.383981  0.511918  0.697366  0.664157   \n",
       "Input 12 -0.155881 -0.044529 -0.156283 -0.165669 -0.219152 -0.190464   \n",
       "\n",
       "           Input 7   Input 8   Input 9  Input 10  Input 11  Input 12  \n",
       "Input 1   0.691514  0.665115  0.738312  0.686954  0.454579 -0.155881  \n",
       "Input 2  -0.455466 -0.458217 -0.459051 -0.417590 -0.325162 -0.044529  \n",
       "Input 3   0.582291  0.558866  0.635272  0.583224  0.383981 -0.156283  \n",
       "Input 4   0.723526  0.711352  0.802887  0.751508  0.511918 -0.165669  \n",
       "Input 5   0.924553  0.913517  0.971557  0.881586  0.697366 -0.219152  \n",
       "Input 6   0.773119  0.761403  0.853061  0.801882  0.664157 -0.190464  \n",
       "Input 7   1.000000  0.946761  0.874562  0.807780  0.526361 -0.234400  \n",
       "Input 8   0.946761  1.000000  0.878703  0.806569  0.548836 -0.250512  \n",
       "Input 9   0.874562  0.878703  1.000000  0.882846  0.762006 -0.239315  \n",
       "Input 10  0.807780  0.806569  0.882846  1.000000  0.703079 -0.183873  \n",
       "Input 11  0.526361  0.548836  0.762006  0.703079  1.000000 -0.085909  \n",
       "Input 12 -0.234400 -0.250512 -0.239315 -0.183873 -0.085909  1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46406b2",
   "metadata": {},
   "source": [
    "### Input 5 and Input 9 are the two inputs most closely related"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ee568",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "### 6) TO DO: Plot bar charts using pandas dataframe (plot the mean value of the sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d99a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean values are:\n",
      "Input 1     3.708112\n",
      "Input 2     1.860839\n",
      "Input 3     5.038686\n",
      "Input 4     4.701443\n",
      "Input 5     0.976114\n",
      "Input 6     1.501182\n",
      "Input 7     0.692307\n",
      "Input 8     0.365517\n",
      "Input 9     0.859494\n",
      "Input 10    2.742349\n",
      "Input 11    1.795423\n",
      "Input 12    3.719455\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get column names\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "#excluse last column (class)\n",
    "features=len(columns)-1\n",
    "columns=columns[:features]\n",
    "\n",
    "#get and print the means of all sensors \n",
    "print('The mean values are:\\n{}'.format(df.mean(numeric_only=True)))\n",
    "\n",
    "#store mean values\n",
    "mean_values=df[:].mean(numeric_only=True)\n",
    "\n",
    "#plot the data with bar charts\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(columns, mean_values )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32525a42",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### 7) TO DO: Create Feature Matrix and Target Vector\n",
    "\"Features\" are also known as predictors, inputs, or attributes. The \"response\" is also known as the target, label, or output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64394fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['Input 1', 'Input 2', 'Input 3', 'Input 4', 'Input 5', 'Input 6', 'Input 7', 'Input 8', 'Input 9', 'Input 10','Input 11', 'Input 12']].values\n",
    "y=df['class'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc02fa",
   "metadata": {},
   "source": [
    "### 8) TO DO: Convert the features dataframe to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31d5e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb5256",
   "metadata": {},
   "source": [
    "### 9) TO DO: Label Encoding\n",
    "Transform the categorical labels into integers using the scikit-learn label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb8718e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes: ['one' 'three' 'two']\n",
      "Encoded values (slice): [0 0 0 0 0 0 0 0 0 0]\n",
      "Encoded shape: (1732,)\n"
     ]
    }
   ],
   "source": [
    "#import label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming y is your target vector containing categorical class labels\n",
    "\n",
    "#instantiate integer encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#encode the class labels\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "#print the categorical class labels we encoded (note the underscore)\n",
    "print('Encoded classes:', label_encoder.classes_)\n",
    "\n",
    "#print a few encoded values using python slice\n",
    "print('Encoded values (slice):', y_encoded[:10])  # Example: Print the first 10 encoded values\n",
    "\n",
    "#print the shape of the encoded classes\n",
    "print('Encoded shape:', y_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81234e86",
   "metadata": {},
   "source": [
    "### 10) TO DO: Split the data into Training and Testing Sets\n",
    "Scikit learn contains a function called the train_test_split function that will randomly shuffle the dataset and then splits it into two datasets: a\n",
    "training set used to build the model and a test set to assess and evaluate how well the model works on unseen data (also called outof=sample data).\n",
    "#### Use a 80% / 20% train/test split for this project.\n",
    "NOTE: You must use the encoded class labels in this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db373b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_array is your feature matrix as a NumPy array and y_encoded is your encoded target vector\n",
    "\n",
    "# Split the data into training and testing sets with an 80% / 20% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a523072b",
   "metadata": {},
   "source": [
    "### 11) TO DO:Look at the shape of the data (rows and columns) after splitting it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a1a7651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1385, 12)\n",
      "y_train shape: (1385,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d512503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (347, 12)\n",
      "y_test shape: (347,)\n"
     ]
    }
   ],
   "source": [
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02672e8a",
   "metadata": {},
   "source": [
    "## Scale the Data\n",
    "#### IMPORTANT: Standardizing the features:\n",
    "Standardization of datasets (feature scaling) is a common requirement for many machine learning and optimization algorithms implemented in\n",
    "scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data, i.e., Gaussian\n",
    "with zero mean and unit variance.\n",
    "### 12) TO DO: Let's use the StandarScaler from Scikit-learn to transform (scale) our feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "766c9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3351f2",
   "metadata": {},
   "source": [
    "### A comment on what the above code does \n",
    "Using the preceding code, we loaded the StandardScaler class from the preprocessing module and initialized a new StandardScaler object\n",
    "that we assigned to the variable sc.\n",
    "Using the fit method, StandardScaler estimated the parameters  (sample mean) and (standard deviation) for each feature dimension\n",
    "from the training data.\n",
    "By calling the transform method, we then standardized the training data using those estimated parameters  and .\n",
    "Note that we used the same scaling parameters to standardize the test set so that both the values in the training and test dataset are\n",
    "comparable to each other.\n",
    "##### IMPORTANT: So from this point forward you must use the scaled training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac4118",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "#### Train multiple Machine Learning models during same session. You will use the three algorithms from previous labs.\n",
    "1. K-Nearest Neighbor (with K=10, K=50, K=200)\n",
    "2. Logistic Regression\n",
    "3. Linear Support Vector Classifier\n",
    "\n",
    "During the evaluation phase you must predict class member propbabilities and comment on what they mean.This means that scikit-learns\n",
    "linear support vector classifier cannot be used for those prodictions since this model does not have a method to predict class membership\n",
    "probabilities, but like the other models, it does have the same predict method.\n",
    "- You MUST properly use model evaluation metrics (accuracy, confusion matrix, etc.)\n",
    "- Two of your models (KNN and Logistic Regression MUST predict class membership probabilities and associated class label names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5176a7f",
   "metadata": {},
   "source": [
    "## Build a KNN Classification Model for K = 10, 50 and 200\n",
    "### 13) TO DO: In the sections below you should build and train the actual machine learning model.\n",
    "#### In the cell below: enter the code to import, instantiate, fit, predict and test the model's performance (accuracy) for the K-Nearest\n",
    "Neighbor Model in SciKit-Learn for K= 10, 50 and 200. This should be completed in ONE cell using a loop, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3494e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 10, Accuracy = 0.9769\n",
      "K = 50, Accuracy = 0.9366\n",
      "K = 200, Accuracy = 0.8617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the values of K\n",
    "k_values = [10, 50, 200]\n",
    "\n",
    "# Iterate over each K value and build/train/test the model\n",
    "for k in k_values:\n",
    "    # Instantiate the KNN classifier with the current K value\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the accuracy for the current K value\n",
    "    print(f'K = {k}, Accuracy = {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce58acd",
   "metadata": {},
   "source": [
    "#### Predicting class-membership probabilites\n",
    "Scikit-Learn has a method that allows prediction of class member probabilities.\n",
    "- The probability that training examples belong to a certain class can be computed using the predict_proba method. For example, we canpredict the probabilities of the first three samples in the test set as follows (NOTE: X_test_std[:3. :] means get the first 3 rows and the associated columns from the test dataset X_test):\n",
    "\n",
    "\n",
    "In the cells below, your must predict the class-membership probabilities for each specified SINGLE ROW OF DATA\n",
    "Also, you should recall that the label encoding that we implemented earlier resulted in the mapping:\n",
    "class membership label indices after encoding\n",
    "\n",
    "<p style=\"text-indent: 25px;\"> 0 = 'one' (the Substance is Substance 1)</p>\n",
    "<p style=\"text-indent: 25px;\"> 1 = 'three' (false alarm)</p>\n",
    "<p style=\"text-indent: 25px;\"> 2 = 'two' (The Substance is Substance 2)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85233d5d",
   "metadata": {},
   "source": [
    "### 14) TO DO:class-membership probability\n",
    "Predict the class membership probability by using the a row with index = 10 from the X_test_std data. Make sure your print statement uses a\n",
    "complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad496608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class membership probabilities for the sample row (index = 10) are:\n",
      "Class 0: 0.9550\n",
      "Class 1: 0.0000\n",
      "Class 2: 0.0450\n",
      "\n",
      "The correct class label from y_test for the sample row (index = 10) is: 2\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_test_std is your standardized test data and knn_classifier is your trained KNN classifier\n",
    "\n",
    "# Get the row with index = 10 from X_test_std\n",
    "sample_row = X_test_std[10].reshape(1, -1)  # Reshape to a 2D array as required by predict_proba\n",
    "\n",
    "# Predict the class membership probability for the sample row\n",
    "class_probabilities = knn_classifier.predict_proba(sample_row)\n",
    "\n",
    "# Print the predicted class membership probabilities\n",
    "print(f\"The predicted class membership probabilities for the sample row (index = 10) are:\")\n",
    "for class_label, probability in zip(knn_classifier.classes_, class_probabilities[0]):\n",
    "    print(f\"Class {class_label}: {probability:.4f}\")\n",
    "\n",
    "# Compare with the correct answer from y_test\n",
    "correct_class = y_test[10]\n",
    "print(f\"\\nThe correct class label from y_test for the sample row (index = 10) is: {correct_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9bdc8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class membership probabilities for the sample row (index = 125) are:\n",
      "Class 0: 0.9600\n",
      "Class 1: 0.0000\n",
      "Class 2: 0.0400\n",
      "\n",
      "The correct class label from y_test for the sample row (index = 125) is: 2\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_test_std is your standardized test data and knn_classifier is your trained KNN classifier\n",
    "\n",
    "# Get the row with index = 125 from X_test_std\n",
    "sample_row = X_test_std[125].reshape(1, -1)  # Reshape to a 2D array as required by predict_proba\n",
    "\n",
    "# Predict the class membership probability for the sample row\n",
    "class_probabilities = knn_classifier.predict_proba(sample_row)\n",
    "\n",
    "# Print the predicted class membership probabilities\n",
    "print(\"The predicted class membership probabilities for the sample row (index = 125) are:\")\n",
    "for class_label, probability in zip(knn_classifier.classes_, class_probabilities[0]):\n",
    "    print(f\"Class {class_label}: {probability:.4f}\")\n",
    "\n",
    "# Compare with the correct answer from y_test\n",
    "correct_class = y_test[125]\n",
    "print(f\"\\nThe correct class label from y_test for the sample row (index = 125) is: {correct_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea0ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
